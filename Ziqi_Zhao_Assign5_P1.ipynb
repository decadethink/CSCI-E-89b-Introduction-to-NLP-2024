{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2529894d-6da7-47be-9b52-f729a6157e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# URL of the Gutenberg webpage\n",
    "url = \"https://www.gutenberg.org/cache/epub/36/pg36-images.html#chap03\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    paragraph_list = [p.get_text(strip=True) for p in paragraphs]\n",
    "else:\n",
    "    raise Exception(\"Failed to retrieve the webpage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5bb2c0-e437-412c-b727-02d21dd2d600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed smaller text (as integers): [3, 10, 5, 6, 1, 5, 6, 1, 4, 1, 6, 4, 14, 18, 11, 2, 1, 6, 14, 4, 11, 11, 1, 3, 2, 28, 3, 1, 17, 5, 3, 10, 1, 7, 2, 17, 1, 15, 10, 4, 9, 4, 15, 3, 2, 9, 6, 1, 11, 5]\n",
      "\n",
      "Character mapping: {' ': 1, 'e': 2, 't': 3, 'a': 4, 'i': 5, 's': 6, 'n': 7, 'o': 8, 'r': 9, 'h': 10, 'l': 11, 'd': 12, 'u': 13, 'm': 14, 'c': 15, 'f': 16, 'w': 17, 'p': 18, 'g': 19, 'y': 20, '\\r': 21, '\\n': 22, ',': 23, 'b': 24, 'v': 25, '.': 26, 'k': 27, 'x': 28, '—': 29, '-': 30, '0': 31, 'q': 32, 'z': 33, 'j': 34, ';': 35, '!': 36, '3': 37, '5': 38, '?': 39, '1': 40, '8': 41, '9': 42, '4': 43, '2': 44, '“': 45, '”': 46, ':': 47, '’': 48, '@': 49, '$': 50, '#': 51, '%': 52}\n"
     ]
    }
   ],
   "source": [
    "# Part (a)\n",
    "\n",
    "# Select 10 paragraphs for the large text dataset\n",
    "large_text = ' '.join(paragraph_list[8:18]).lower()\n",
    "\n",
    "# Define a smaller text with some new characters or symbols\n",
    "small_text = \"This is a sample small text with new characters like !, @, $, #, %.\".lower()\n",
    "\n",
    "# Combine both texts for tokenizer to capture all characters\n",
    "combined_text = large_text + ' ' + small_text\n",
    "\n",
    "# Tokenize by character level\n",
    "tokenizer = Tokenizer(char_level=True)\n",
    "tokenizer.fit_on_texts([combined_text])\n",
    "\n",
    "# Convert texts to sequences of integers\n",
    "large_text_seq = tokenizer.texts_to_sequences([large_text])[0]\n",
    "small_text_seq = tokenizer.texts_to_sequences([small_text])[0]\n",
    "\n",
    "# Display some samples from the smaller text\n",
    "print(\"Processed smaller text (as integers):\", small_text_seq[:50])\n",
    "\n",
    "# Character to integer mapping\n",
    "char_index = tokenizer.word_index\n",
    "print(\"\\nCharacter mapping:\", char_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9270f44-9ba8-48e2-aebf-83dca6f3e8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.6948\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.2248\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0669\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0213\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0075\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0030\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0013\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 5.9316e-04\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 2.9697e-04\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 1.5835e-04\n",
      "Embedded representation of the smaller text: [[-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      "  -0.0312106  -0.02451975]\n",
      " [ 0.02603345 -0.03320745 -0.03595594  0.03306324  0.0279299   0.05295893\n",
      "  -0.01967241 -0.02973782]\n",
      " [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "   0.018551    0.03441832]\n",
      " [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      "  -0.00859764  0.00682296]\n",
      " [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "   0.0397648   0.02453694]\n",
      " [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "   0.018551    0.03441832]\n",
      " [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      "  -0.00859764  0.00682296]\n",
      " [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "   0.0397648   0.02453694]\n",
      " [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "   0.01914291  0.00779086]\n",
      " [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "   0.0397648   0.02453694]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 12:48:47.996535: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    }
   ],
   "source": [
    "# Part (b)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "# Define constants\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim = 8 \n",
    "input_length = len(large_text_seq)  \n",
    "\n",
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Convert sequences to numpy arrays\n",
    "large_text_seq = np.array(large_text_seq).reshape(1, -1)\n",
    "\n",
    "# Train the embedding model\n",
    "model.fit(large_text_seq, np.array([1]), epochs=10, verbose=1)\n",
    "\n",
    "# Get the embedding layer\n",
    "embedding_layer = model.layers[0]\n",
    "\n",
    "# Apply the trained embedding model to the smaller text\n",
    "small_text_seq = np.array(small_text_seq).reshape(1, -1)\n",
    "embeddings = embedding_layer(small_text_seq).numpy()\n",
    "\n",
    "# Display samples of the embedded representation\n",
    "print(\"Embedded representation of the smaller text:\", embeddings[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6780249e-fb08-4982-ac48-5480fa5d47ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Character Embeddings from the Large Text for Shared Characters:\n",
      "Character: 'e' - Embedding: [-0.04226547  0.00950972 -0.03681732  0.04905974  0.00763726 -0.03691835\n",
      " -0.04609565  0.02569714]\n",
      "Character: 'x' - Embedding: [-0.01579528  0.03050924 -0.02084445 -0.05173132 -0.01258191 -0.04671421\n",
      " -0.04082201  0.02790914]\n",
      "Character: 'c' - Embedding: [-0.0427279  -0.03716389 -0.05652898 -0.02804159 -0.00986847 -0.00887603\n",
      " -0.0466985  -0.04726185]\n",
      "Character: 'p' - Embedding: [-0.04411635  0.02783827  0.03957607  0.0565103   0.03599318  0.04962989\n",
      "  0.05234342  0.04529336]\n",
      "Character: 't' - Embedding: [-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      " -0.0312106  -0.02451975]\n",
      "Character: 'w' - Embedding: [-0.00717229 -0.0195091   0.00754918 -0.04615949  0.02726276  0.01619787\n",
      "  0.01306046 -0.01941648]\n",
      "Character: ',' - Embedding: [ 0.01524457  0.03086192 -0.01282921 -0.02874693 -0.02800214  0.05083368\n",
      "  0.0360284   0.03180785]\n",
      "Character: 'l' - Embedding: [-0.02413644 -0.03710373 -0.03097159 -0.01369297  0.04531087  0.05139328\n",
      " -0.03126061  0.01374027]\n",
      "Character: 's' - Embedding: [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      " -0.00859764  0.00682296]\n",
      "Character: 'm' - Embedding: [ 0.04208065  0.01012066  0.03004844 -0.01000585  0.02731164 -0.0532513\n",
      "  0.04369945 -0.04806934]\n",
      "Character: '.' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: 'n' - Embedding: [-0.01256536  0.04429641  0.0573497   0.02838137 -0.03121702  0.05202634\n",
      " -0.04411198 -0.03486205]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'k' - Embedding: [ 0.01231498 -0.04222181 -0.02636105  0.03413659  0.03140458  0.04203451\n",
      "  0.03693087  0.04102923]\n",
      "Character: 'r' - Embedding: [-0.03207099 -0.00181873 -0.00762464 -0.02368955 -0.01908734  0.04262458\n",
      " -0.03449012 -0.05648727]\n",
      "Character: 'h' - Embedding: [ 0.02603345 -0.03320745 -0.03595594  0.03306324  0.0279299   0.05295893\n",
      " -0.01967241 -0.02973782]\n",
      "Character: '!' - Embedding: [ 0.02951811 -0.03222122 -0.00182674  0.02728106  0.00389671 -0.03202302\n",
      "  0.01196955  0.03791349]\n",
      "Character: 'i' - Embedding: [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "  0.018551    0.03441832]\n",
      "Character: 'a' - Embedding: [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "  0.01914291  0.00779086]\n",
      "\n",
      "Character Embeddings for the Small Text:\n",
      "Character: 't' - Embedding: [-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      " -0.0312106  -0.02451975]\n",
      "Character: 'h' - Embedding: [ 0.02603345 -0.03320745 -0.03595594  0.03306324  0.0279299   0.05295893\n",
      " -0.01967241 -0.02973782]\n",
      "Character: 'i' - Embedding: [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "  0.018551    0.03441832]\n",
      "Character: 's' - Embedding: [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      " -0.00859764  0.00682296]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'i' - Embedding: [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "  0.018551    0.03441832]\n",
      "Character: 's' - Embedding: [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      " -0.00859764  0.00682296]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'a' - Embedding: [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "  0.01914291  0.00779086]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 's' - Embedding: [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      " -0.00859764  0.00682296]\n",
      "Character: 'a' - Embedding: [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "  0.01914291  0.00779086]\n",
      "Character: 'm' - Embedding: [ 0.04208065  0.01012066  0.03004844 -0.01000585  0.02731164 -0.0532513\n",
      "  0.04369945 -0.04806934]\n",
      "Character: 'p' - Embedding: [-0.04411635  0.02783827  0.03957607  0.0565103   0.03599318  0.04962989\n",
      "  0.05234342  0.04529336]\n",
      "Character: 'l' - Embedding: [-0.02413644 -0.03710373 -0.03097159 -0.01369297  0.04531087  0.05139328\n",
      " -0.03126061  0.01374027]\n",
      "Character: 'e' - Embedding: [-0.04226547  0.00950972 -0.03681732  0.04905974  0.00763726 -0.03691835\n",
      " -0.04609565  0.02569714]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 's' - Embedding: [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      " -0.00859764  0.00682296]\n",
      "Character: 'm' - Embedding: [ 0.04208065  0.01012066  0.03004844 -0.01000585  0.02731164 -0.0532513\n",
      "  0.04369945 -0.04806934]\n",
      "Character: 'a' - Embedding: [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "  0.01914291  0.00779086]\n",
      "Character: 'l' - Embedding: [-0.02413644 -0.03710373 -0.03097159 -0.01369297  0.04531087  0.05139328\n",
      " -0.03126061  0.01374027]\n",
      "Character: 'l' - Embedding: [-0.02413644 -0.03710373 -0.03097159 -0.01369297  0.04531087  0.05139328\n",
      " -0.03126061  0.01374027]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 't' - Embedding: [-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      " -0.0312106  -0.02451975]\n",
      "Character: 'e' - Embedding: [-0.04226547  0.00950972 -0.03681732  0.04905974  0.00763726 -0.03691835\n",
      " -0.04609565  0.02569714]\n",
      "Character: 'x' - Embedding: [-0.01579528  0.03050924 -0.02084445 -0.05173132 -0.01258191 -0.04671421\n",
      " -0.04082201  0.02790914]\n",
      "Character: 't' - Embedding: [-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      " -0.0312106  -0.02451975]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'w' - Embedding: [-0.00717229 -0.0195091   0.00754918 -0.04615949  0.02726276  0.01619787\n",
      "  0.01306046 -0.01941648]\n",
      "Character: 'i' - Embedding: [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "  0.018551    0.03441832]\n",
      "Character: 't' - Embedding: [-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      " -0.0312106  -0.02451975]\n",
      "Character: 'h' - Embedding: [ 0.02603345 -0.03320745 -0.03595594  0.03306324  0.0279299   0.05295893\n",
      " -0.01967241 -0.02973782]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'n' - Embedding: [-0.01256536  0.04429641  0.0573497   0.02838137 -0.03121702  0.05202634\n",
      " -0.04411198 -0.03486205]\n",
      "Character: 'e' - Embedding: [-0.04226547  0.00950972 -0.03681732  0.04905974  0.00763726 -0.03691835\n",
      " -0.04609565  0.02569714]\n",
      "Character: 'w' - Embedding: [-0.00717229 -0.0195091   0.00754918 -0.04615949  0.02726276  0.01619787\n",
      "  0.01306046 -0.01941648]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'c' - Embedding: [-0.0427279  -0.03716389 -0.05652898 -0.02804159 -0.00986847 -0.00887603\n",
      " -0.0466985  -0.04726185]\n",
      "Character: 'h' - Embedding: [ 0.02603345 -0.03320745 -0.03595594  0.03306324  0.0279299   0.05295893\n",
      " -0.01967241 -0.02973782]\n",
      "Character: 'a' - Embedding: [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "  0.01914291  0.00779086]\n",
      "Character: 'r' - Embedding: [-0.03207099 -0.00181873 -0.00762464 -0.02368955 -0.01908734  0.04262458\n",
      " -0.03449012 -0.05648727]\n",
      "Character: 'a' - Embedding: [ 0.02352492 -0.03851312 -0.02123908 -0.02921253  0.04843098 -0.03126992\n",
      "  0.01914291  0.00779086]\n",
      "Character: 'c' - Embedding: [-0.0427279  -0.03716389 -0.05652898 -0.02804159 -0.00986847 -0.00887603\n",
      " -0.0466985  -0.04726185]\n",
      "Character: 't' - Embedding: [-0.02512773 -0.04524183 -0.04393537  0.03889078 -0.05544361  0.03904049\n",
      " -0.0312106  -0.02451975]\n",
      "Character: 'e' - Embedding: [-0.04226547  0.00950972 -0.03681732  0.04905974  0.00763726 -0.03691835\n",
      " -0.04609565  0.02569714]\n",
      "Character: 'r' - Embedding: [-0.03207099 -0.00181873 -0.00762464 -0.02368955 -0.01908734  0.04262458\n",
      " -0.03449012 -0.05648727]\n",
      "Character: 's' - Embedding: [-0.05525877  0.03881495  0.03274475  0.03385846 -0.02314739 -0.04105077\n",
      " -0.00859764  0.00682296]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: 'l' - Embedding: [-0.02413644 -0.03710373 -0.03097159 -0.01369297  0.04531087  0.05139328\n",
      " -0.03126061  0.01374027]\n",
      "Character: 'i' - Embedding: [ 0.0343282   0.02563981 -0.01774368  0.02292908 -0.03180461 -0.01492068\n",
      "  0.018551    0.03441832]\n",
      "Character: 'k' - Embedding: [ 0.01231498 -0.04222181 -0.02636105  0.03413659  0.03140458  0.04203451\n",
      "  0.03693087  0.04102923]\n",
      "Character: 'e' - Embedding: [-0.04226547  0.00950972 -0.03681732  0.04905974  0.00763726 -0.03691835\n",
      " -0.04609565  0.02569714]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: '!' - Embedding: [ 0.02951811 -0.03222122 -0.00182674  0.02728106  0.00389671 -0.03202302\n",
      "  0.01196955  0.03791349]\n",
      "Character: ',' - Embedding: [ 0.01524457  0.03086192 -0.01282921 -0.02874693 -0.02800214  0.05083368\n",
      "  0.0360284   0.03180785]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: '@' - Embedding: [-0.00826821  0.0403882  -0.03441399 -0.02932221  0.04254315 -0.01115794\n",
      " -0.0497098  -0.01609872]\n",
      "Character: ',' - Embedding: [ 0.01524457  0.03086192 -0.01282921 -0.02874693 -0.02800214  0.05083368\n",
      "  0.0360284   0.03180785]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: '$' - Embedding: [ 0.04472211  0.02370617  0.02987594  0.03374488  0.00883087 -0.01830067\n",
      " -0.01547128  0.02037816]\n",
      "Character: ',' - Embedding: [ 0.01524457  0.03086192 -0.01282921 -0.02874693 -0.02800214  0.05083368\n",
      "  0.0360284   0.03180785]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: '#' - Embedding: [-0.0443912   0.01276039  0.0006515   0.02184523  0.0237218   0.02476461\n",
      " -0.00806763  0.02625188]\n",
      "Character: ',' - Embedding: [ 0.01524457  0.03086192 -0.01282921 -0.02874693 -0.02800214  0.05083368\n",
      "  0.0360284   0.03180785]\n",
      "Character: ' ' - Embedding: [-0.01968647  0.05395486 -0.05481583  0.02182067  0.03086295  0.02956053\n",
      "  0.0397648   0.02453694]\n",
      "Character: '%' - Embedding: [-0.04761132  0.02201852  0.04796803  0.00834887 -0.04337293 -0.04170382\n",
      " -0.03972606 -0.04597832]\n",
      "Character: '.' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n"
     ]
    }
   ],
   "source": [
    "# Part (c)\n",
    "\n",
    "# Extract the embedding weights from the embedding layer\n",
    "embedding_weights = embedding_layer.get_weights()[0]\n",
    "\n",
    "# Function to get embeddings for characters\n",
    "def get_char_embeddings(char_seq, char_index, embedding_weights):\n",
    "    for char, idx in char_index.items():\n",
    "        if idx < len(embedding_weights):  \n",
    "            print(f\"Character: '{char}' - Embedding: {embedding_weights[idx]}\")\n",
    "\n",
    "# Show embeddings for the common characters between large and small text\n",
    "print(\"\\nCharacter Embeddings from the Large Text for Shared Characters:\")\n",
    "shared_chars = set(large_text) & set(small_text)  # Find common characters\n",
    "for char in shared_chars:\n",
    "    idx = char_index[char]\n",
    "    print(f\"Character: '{char}' - Embedding: {embedding_weights[idx]}\")\n",
    "\n",
    "# Show embeddings for the small text\n",
    "print(\"\\nCharacter Embeddings for the Small Text:\")\n",
    "for char in small_text:\n",
    "    if char in char_index:\n",
    "        idx = char_index[char]\n",
    "        print(f\"Character: '{char}' - Embedding: {embedding_weights[idx]}\")\n",
    "    else:\n",
    "        print(f\"Character: '{char}' is out-of-vocabulary.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3de79a7-cbe7-453d-88c0-07b08be5a28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Handling New Characters in the Smaller Text:\n",
      "Character: '^' is out-of-vocabulary (OOV).\n",
      "Character: '^' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: '&' is out-of-vocabulary (OOV).\n",
      "Character: '&' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: '*' is out-of-vocabulary (OOV).\n",
      "Character: '*' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: '(' is out-of-vocabulary (OOV).\n",
      "Character: '(' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: ')' is out-of-vocabulary (OOV).\n",
      "Character: ')' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: '_' is out-of-vocabulary (OOV).\n",
      "Character: '_' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n",
      "Character: '+' is out-of-vocabulary (OOV).\n",
      "Character: '+' - Embedding: [-0.0289985   0.04180746  0.00819798 -0.02336457 -0.04074388 -0.00334794\n",
      "  0.02192151  0.04228214]\n"
     ]
    }
   ],
   "source": [
    "# Part (d): Handling New Characters\n",
    "new_small_text = \"^&*()_+\"\n",
    "new_small_text_seq = tokenizer.texts_to_sequences([new_small_text])[0]\n",
    "\n",
    "print(\"\\nHandling New Characters in the Smaller Text:\")\n",
    "for char in new_small_text:\n",
    "    if char in char_index:\n",
    "        idx = char_index[char]\n",
    "        print(f\"Character: '{char}' - Embedding: {embedding_weights[idx]}\")\n",
    "    else:\n",
    "        print(f\"Character: '{char}' is out-of-vocabulary (OOV).\")\n",
    "        print(f\"Character: '{char}' - Embedding: {embedding_weights[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53979b1d-6b01-442e-a9d9-d230aa3ce231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
